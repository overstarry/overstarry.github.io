<!doctype html><html lang=zh dir=auto><head><meta name=generator content="Hugo 0.151.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Overstarry Site</title><meta name=keywords content="overstarry,hugo,ai assistants,mcp,blog"><meta name=description content="Overstarry 记录 AI 助理、MCP 集成与个人开发总结的 Hugo 博客"><meta name=author content="overstarry"><link rel=canonical href=https://jasminides.com/><meta name=google-site-verification content="gfdsdx"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=https://jasminides.com/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://jasminides.com/img/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jasminides.com/img/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jasminides.com/img/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://jasminides.com/img/favicon/apple-touch-icon.png><link rel=mask-icon href=https://jasminides.com/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://jasminides.com/index.xml><link rel=alternate type=application/json href=https://jasminides.com/index.json><link rel=alternate hreflang=zh href=https://jasminides.com/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-G40XG2SPQN"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-G40XG2SPQN")}</script><meta property="og:url" content="https://jasminides.com/"><meta property="og:site_name" content="Overstarry Site"><meta property="og:title" content="Overstarry Site"><meta property="og:description" content="Overstarry 记录 AI 助理、MCP 集成与个人开发总结的 Hugo 博客"><meta property="og:locale" content="zh"><meta property="og:type" content="website"><meta property="og:image" content="https://jasminides.com/img/generics1-fs8.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jasminides.com/img/generics1-fs8.png"><meta name=twitter:title content="Overstarry Site"><meta name=twitter:description content="Overstarry 记录 AI 助理、MCP 集成与个人开发总结的 Hugo 博客"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Overstarry Site","url":"https://jasminides.com/","description":"Overstarry 记录 AI 助理、MCP 集成与个人开发总结的 Hugo 博客","logo":"https://jasminides.com/img/favicon/favicon.ico","sameAs":["https://github.com/overstarry","https://stackoverflow.com/users/8867029/overstarry"]}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2240998016636586" crossorigin=anonymous></script><link rel=manifest href=https://jasminides.com/site.webmanifest></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jasminides.com/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://jasminides.com/archives/ title=archives><span>archives</span></a></li><li><a href=https://jasminides.com/tags/ title=tags><span>tags</span></a></li><li><a href=https://jasminides.com/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://jasminides.com/index.xml title=rss><span>rss</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Kubernetes 系统资源预留</h2></header><div class=entry-content><p>前言 Kubernetes 的 pod 可以按照节点的资源进行调度，默认情况下 pod 能够使用节点的全部资源，这样往往会出现因为节点自身运行的一些驱动及 Kubernetes 系统守护进程，导致资源不足的问题。 例如有一个应用在运行中使用了大量的系统资源，导致 kubelet 和 apiserver 的心跳出现故障，导致节点处于 Not Ready 的状态，节点出现 Not Ready 的状况后，过一会儿会将 pod 调度到其它 node 节点上运行，往往会导致节点雪崩，一个接一个的出现 Not Ready 状况。
那么如何解决这个问题呢？这时可以通过 为 Kubernetes 集群配置资源预留，kubelet 暴露了一个名为 Node Allocatable 的特性，有助于为系统守护进程预留计算资源，Kubernetes 也是推荐集群管理员按照每个节点上的工作负载来配置 Node Allocatable。
Node Allocatable Kubernetes 节点上的 Allocatable 被定义为 Pod 可用计算资源量。调度器不会超额申请 Allocatable。目前支持 CPU、内存 和 存储 这几个参数。可以通过 kubectl describe node 命令查看节点可分配资源的数据： 可以看到有 Capacity 和 Allocatable 两个内容，Allocatable 这个就是节点可分配资源，由于没有设置，所以默认 Capacity 和 Allocatable 是一致的。
Capacity 是节点所有的系统资源，kube-reserved 是给 kube 组件预留的资源，system-reserved 是给系统进程预留的资源，eviction-hard 是 Kubelet 的驱逐阈值。
...</p></div><footer class=entry-footer><span title='2024-03-09 21:23:52 +0800 +0800'>三月 9, 2024</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to Kubernetes 系统资源预留" href=https://jasminides.com/posts/kubernetes-%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90%E9%A2%84%E7%95%99/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>atop 工具介绍及使用</h2></header><div class=entry-content><p>前言 最近出现了服务器 cpu、内存升高导致服务器宕机的问题，发生宕机后，往往由于对系统资源数据收集的不齐全，导致无法快速查明发生宕机的原因。在通过云厂商客服和网络相关资料帮助下，了解了 atop 这个工具，本机对 atop 的安装及使用进行介绍。
atop 介绍 atop 是一款用于监控 Linux 系统资源与进程的工具，能够报告所有进程的活动。其以一定的频率记录系统和进程活动，采集的数据包含 CPU、内存、磁盘、网络的资源使用情况和进程运行情况，并能以日志文件的方式保存在磁盘中。对于每个进程，会显示 CPU 使用率、内存增长、磁盘使用率、优先级、用户名、状态和退出码等。当服务器出现问题后，可以根据相应的 atop 日志文件进行分析。
安装 atop 不是系统的内部自带命令，需要进行安装，接下来以 Ubuntu 系统为例子，介绍如何安装 atop 命令。
1 更新软件源
执行 sudo apt update 进行软件源的更新。
2 安装 atop
执行 sudo apt install atop 命令安装 atop。
配置 安装完 atop 后，可以使用 atop 的默认配置使用，也可根据使用情况修改默认配置，atop 默认配置在 /etc/sysconfig/atop,查看默认配置文件内容：
# /etc/default/atop # see man atoprc for more possibilities to configure atop execution LOGOPTS="-R" LOGINTERVAL=600 LOGGENERATIONS=28 LOGPATH=/var/log/atop LOGINTERVAL 是监控周期，默认 600s，LOGGENERATIONS 是日志文件保留周期，默认是 28 天，可以根据具体的需求进行修改。
...</p></div><footer class=entry-footer><span title='2024-03-02 17:32:25 +0800 +0800'>三月 2, 2024</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to atop 工具介绍及使用" href=https://jasminides.com/posts/atop-%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Kubernetes ExternalName</h2></header><div class=entry-content><p>前言 我们知道 kubernetes 内部服务之间是通过 service 进行相互访问的，那么如果现在有一个非 kubernetes 部署的服务，我们可以也通过 service 进行内部交互使用吗？答案是可以，我们可以使用 service 的 ExternalName 类型将 service 映射到外部服务上。
最近需要将一个外部服务映射到 kubernetes service 上，通过查找资料学习，本文记录如何将 kubernetes service 映射到外部服务的流程步骤。
外部域名映射内部 service 先讲解如何将外部服务通过域名的方式映射到内部 service 上，通过配置 externalName 字段来配置映射关系。例如，以下 Service 定义将 test 命名空间中的 my-service 服务映射到 my.overstarry.vip:
apiVersion: v1 kind: Service metadata: name: my-service namespace: test spec: type: ExternalName externalName: my.overstarry.vip 虽然 externalName 也支持填写 ip 地址，但不会被 kubernetes 解析，如果需要使用 ip 地址，可以使用无头服务 Headless，下文会进行介绍。
外部服务 ip 映射 service 接下来介绍没有域名的外部服务和 service 如何进行映射。上文讲过虽然 externalName 也支持填写 ip 地址，但不会被 kubernetes 解析，如果需要，则应该使用 Headless Service 进行映射。
...</p></div><footer class=entry-footer><span title='2024-02-24 13:52:30 +0800 +0800'>二月 24, 2024</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to Kubernetes ExternalName" href=https://jasminides.com/posts/kubernetes-externalname/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Go 刷新 cdn</h2></header><div class=entry-content><p>前言 cdn 刷新是 cdn 使用过程中的一项重要的功能，通过刷新功能，您可以删除 CDN 节点上已经缓存的资源，并强制 CDN 节点回源站获取最新资源，适用于源站资源更新和发布、违规资源清理、域名配置变更等。
接下来将分别讲述 阿里云 CDN、AWS cloudfront、Cloudflare cdn 使用 go 语言进行 cdn 的刷新操作的。
阿里云刷新 cdn 如何刷新 阿里云 cdn 的缓存呢？只需使用 阿里云 openapi 的 go sdk 即可，通过查阅文档，我们只需使用 RefreshObjectCaches API 即可刷新阿里云 cdn 的缓存，RefreshObjectCaches 有以下参数：
ObjectPath: 刷新的url ,多个 url 使用换行符进行分隔 ObjectType: 刷新任务的类型，有以下类型 File（默认值）：文件刷新。 Directory：目录刷新。 Regex：正则刷新。 IgnoreParams：去参数刷新。去参数指的是去除请求 URL 中?及?之后的参数，去参数刷新指的是用户先通过接口提交去参数后的 URL，然后用户提交的待刷新 URL 将会与已缓存资源的 URL 进行去参数匹配，如果已缓存资源的 URL 去参数以后与待刷新 URL 匹配，那么 CDN 节点将对缓存资源执行刷新处理。 Force: 当回源内容和源站资源对比后不一致时，是否刷新对应目录下的资源。默认为 false。 下面是一个例子：
package main import ( cdn20180510 "github.com/alibabacloud-go/cdn-20180510/v4/client" openapi "github.com/alibabacloud-go/darabonba-openapi/v2/client" util "github.com/alibabacloud-go/tea-utils/v2/service" "github.com/alibabacloud-go/tea/tea" "os" ) func CreateClient(accessKeyId *string, accessKeySecret *string) (result *cdn20180510.Client, err error) { config := &amp;openapi.Config{ AccessKeyId: accessKeyId, AccessKeySecret: accessKeySecret, } config.Endpoint = tea.String("cdn.ap-southeast-1.aliyuncs.com") result = &amp;cdn20180510.Client{} result, err = cdn20180510.NewClient(config) return result, err } func main() { client, err := CreateClient(tea.String(os.Getenv("ALIBABA_CLOUD_ACCESS_KEY_ID")), tea.String(os.Getenv("ALIBABA_CLOUD_ACCESS_KEY_SECRET"))) if err != nil { return } refreshObjectCachesRequest := &amp;cdn20180510.RefreshObjectCachesRequest{ ObjectPath: tea.String("http://example.com/image/1.png\\\n\t\thttp://aliyundoc.com/image/2.png"), } runtime := &amp;util.RuntimeOptions{} _, err = client.RefreshObjectCachesWithOptions(refreshObjectCachesRequest, runtime) if err != nil { return } return } aws cloudfront 接下来讲解 aws cloudfront 如何刷新 cdn，cloudfront 刷新缓存的操作叫使文件失效，通过查阅 cloudfront 的 API 文档，发现可以使用 CreateInvalidation 来创建失效。可以使用 aws go sdk 来进行操作。
...</p></div><footer class=entry-footer><span title='2024-01-19 22:51:52 +0800 +0800'>一月 19, 2024</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to Go 刷新 cdn" href=https://jasminides.com/posts/go-%E5%88%B7%E6%96%B0-cdn/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Apisix 开启 gzip</h2></header><div class=entry-content><p>最近使用 Apisix 网关时，需要开启 gzip 功能，通过查阅资料学习，了解了几种开启 gzip 的方式，本文记录 2 种 Apisix 开启 gzip 的方式。
gzip 插件 我们可以使用 gzip 插件 针对某些路由开启 gzip，只需对路由使用 gzip 插件并配置一些插件属性即可。
接下来使用一个例子来演示 gzip 插件，使用 apisix admin api 创建一条路由，要注意的是本文的例子是使用 apisix 3.7 版本：
curl -i http://127.0.0.1:9180/apisix/admin/routes \ -H 'X-API-KEY: edd1c9f034335f136f87ad84b625c8f1' -X POST -d ' { "uri": "/get", "plugins": { "gzip": { "buffers": { "number": 8 }, "comp_level": 6, "disable": false, "types": "*" } }, "upstream": { "nodes": [ { "host": "httpbin.org", "port": 443, "weight": 1 } ], "timeout": { "connect": 6, "send": 6, "read": 6 }, "type": "roundrobin", "scheme": "https", "pass_host": "pass", "keepalive_pool": { "idle_timeout": 60, "requests": 1000, "size": 320 } }, "status": 1 }' ...</p></div><footer class=entry-footer><span title='2024-01-13 16:10:31 +0800 +0800'>一月 13, 2024</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to Apisix 开启 gzip" href=https://jasminides.com/posts/apisix-%E5%BC%80%E5%90%AF-gzip/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>如何收集系统宕机后的内存转储信息</h2></header><div class=entry-content><p>前言 最近出现了多次因为各种原因导致的操作系统宕机的问题，为了查找系统宕机的原因，需要收集系统宕机后的内存转储信息。本文就介绍几种常见的方式。
阿里云内置命令收集 由于主要使用的是阿里云的服务器，就先介绍阿里云收集系统宕机内存转储信息的方式。
阿里云系统默认没有开启 dump 配置，我们需要使用以下命令开启：acs-plugin-manager --exec --plugin=ecs_dump_collector --params="--enable"
那我们如何收集内存转储信息呢，执行以下命令：acs-plugin-manager --exec --plugin=ecs_dump_collector --params="-c" 出现以下信息表示收集成功。
有了转储信息文件我们就可以将文件交给专业的运维人员或阿里云工程师进行宕机原因分析。
使用 Crash + Kdump 如果我们没有使用阿里云的服务该如何收集系统崩溃的转储信息呢，我们可以使用 Crash + Kdump 进行收集，通过前面的使用可以看出阿里云的插件就是使用了这两个工具，接下来开始进行简单的介绍。
安装 需要先安装 Crash + Kdump，使用此命令进行安装：
$ sudo apt install linux-crashdump $ sudo apt install crash 安装完为了使服务生效需要重启服务器。
使用以下命令：sudo cat /etc/default/grub.d/kdump-tools.cfg
可以看出系统保留了 192M RAM 内存区供转储捕获内核使用
收集 为了测试方便我们可以使用此命令快速触发崩溃：sudo echo c > /proc/sysrq-trigger 。命令执行后在 /var/crash 目录会生成以当前时间为名称的目录，目录里面就是收集到的转储信息。
demsg.x 为崩溃时候的系统内核日志，dump.x 文件则为转储的内核快照文件。为了更好的查找问题，我们还需要安装 vmlinux，使用以下命令安装：
...</p></div><footer class=entry-footer><span title='2024-01-06 14:46:21 +0800 +0800'>一月 6, 2024</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to 如何收集系统宕机后的内存转储信息" href=https://jasminides.com/posts/%E5%A6%82%E4%BD%95%E6%94%B6%E9%9B%86%E7%B3%BB%E7%BB%9F%E5%AE%95%E6%9C%BA%E5%90%8E%E7%9A%84%E5%86%85%E5%AD%98%E8%BD%AC%E5%82%A8%E4%BF%A1%E6%81%AF/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>go 汉字转拼音 go-pinyin</h2></header><div class=entry-content><p>前言 本文介绍一个 go 汉字转拼音的库 go-pinyin，可以从名字看出这个库的功能就是将汉字转换为相应的拼音。接下来就由我来简单的介绍 go-pinyin。
安装 使用此命令安装：go get github.com/mozillazg/go-pinyin
cli 安装 如果你的 go 版本在 1.17 以下使用此命令安装：go get -u github.com/mozillazg/go-pinyin/cli/pinyin。1.17 及以上版本使用此命令安装：go install github.com/mozillazg/go-pinyin/cli/pinyin@latest。
使用 接下来将分别介绍 cli 的使用和 API 的使用。
cli 使用 安装完在终端输入 pinyin，可以看到使用的方法，尝试一个汉字，可以看到相应的拼音，但也可以看出对多音字的支持有问题。 $ pinyin 中国 zhōng guó $ pinyin 重庆 zhòng qìng 接下来介绍 API 的使用。
api 使用 通过查看文档，可以看出主要是 2 个方法 pinyin.NewArgs 和 pinyin.Pinyin 。
pinyin.NewArgs 创建包含默认配置的 Args, 可以通过修改 Args 的成员来使用不同的模式。
type Args struct { Style int // 拼音风格（默认：Normal) Heteronym bool // 是否启用多音字模式（默认：禁用） Separator string // Slug 中使用的分隔符（默认：-) // 处理没有拼音的字符（默认忽略没有拼音的字符） // 函数返回的 slice 的长度为 0 则表示忽略这个字符 Fallback func(r rune, a Args) []string } pinyin.Pinyin 就是将汉字转为拼音。
...</p></div><footer class=entry-footer><span title='2023-12-23 23:40:04 +0800 +0800'>十二月 23, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to go 汉字转拼音 go-pinyin" href=https://jasminides.com/posts/go-%E6%B1%89%E5%AD%97%E8%BD%AC%E6%8B%BC%E9%9F%B3-go-pinyin/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>mergo 介绍</h2></header><div class=entry-content><p>前言 今天介绍一个 go 库 - mergo, mergo 用来方便的合并 struct 和 map ,可以将结构体的字段赋值到 map 中，可以将 map 的值赋值给结构体的字段。
Mergo 通过在零值字段中设置默认值来合并同类型的 struct 和 map。Mergo 不会合并未导出（私有）字段。它会递归合并任何已导出的字段。它也不会合并 map 中的结构体（因为它们无法使用 Go 反射寻址）。
Mergo 在很多知名项目中被使用，如 containerd、k8s、loki 等。
安装 使用以下命令安装 mergo : go get -u dario.cat/mergo
使用 接下来介绍 mergo 的基础使用和高级用法。
基础使用 mergo 提供了 2 个主要函数：Merge 和 Map, Mergo 用来合并 2 个相同结构的 struct 和 map, Map 用来在结构和 map 之间赋值。
例子：
package main import ( "fmt" "log" "github.com/imdario/mergo" ) type redisConfig struct { Address string Port int DB int UserName string PassWord string } var defaultConfig = redisConfig{ Address: "127.0.0.1", Port: 6379, DB: 1, UserName: "123", PassWord: "123", } func main() { var config redisConfig if err := mergo.Merge(&amp;config, defaultConfig); err != nil { log.Fatal(err) } fmt.Println("redis address: ", config.Address) fmt.Println("redis port: ", config.Port) fmt.Println("redis db: ", config.DB) fmt.Println("redis username: ", config.UserName) fmt.Println("redis password: ", config.PassWord) var m = make(map[string]interface{}) if err := mergo.Map(&amp;m, defaultConfig); err != nil { log.Fatal(err) } fmt.Println(m) } 接下来介绍一些高级用法：
...</p></div><footer class=entry-footer><span title='2023-12-16 22:15:27 +0800 +0800'>十二月 16, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to mergo 介绍" href=https://jasminides.com/posts/mergo-%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>conc 一个更好的 go 并发库</h2></header><div class=entry-content><p>前言 本文介绍 conc - 一个更好的 go 并发库，sourcegraph 在日常开发中使用 go 原生并发出现了问题，由此开发了 conc，相比标准并发代码更优雅，代码更少，下面展示一个例子，可以看出代码减少了许多。
type propagatedPanic struct { val any stack []byte } func main() { done := make(chan *propagatedPanic) go func() { defer func() { if v := recover(); v != nil { done &lt;- &amp;propagatedPanic{ val: v, stack: debug.Stack(), } } else { done &lt;- nil } }() doSomethingThatMightPanic() }() if val := &lt;-done; val != nil { panic(val) } } // conc func main() { var wg conc.WaitGroup wg.Go(doSomethingThatMightPanic) // panics with a nice stacktrace wg.Wait() } 安装 使用以下命令进行安装：go get github.com/sourcegraph/conc
...</p></div><footer class=entry-footer><span title='2023-12-09 23:58:07 +0800 +0800'>十二月 9, 2023</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to conc 一个更好的 go 并发库" href=https://jasminides.com/posts/conc-%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A5%BD%E7%9A%84-go-%E5%B9%B6%E5%8F%91%E5%BA%93/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Kubernetes externaltrafficpolicy 简介</h2></header><div class=entry-content><p>前言 最近在使用 Kubernetes 查看 pod 日志时，发现 pod 日志显示的 ip 不是真实的请求者 ip, 而是 Node 节点的 ip。通过查阅资料发现可以通过设置 externalTrafficPolicy 来显示真实的 IP。
本文对 externaltrafficpolicy 进行一个简单的介绍。
简介 ExternalTrafficPolicy 是 Kubernetes Service 对象的一个属性，它决定了流量如何从集群外部访问 Service。有两个可选值：Cluster 和 Local。
Cluster 模式： 在 Cluster 模式下，流量将通过负载均衡器分发到 Service 的所有 Pod 上。这是传统的负载均衡方式，适用于需要水平扩展和容错的场景。负载均衡器会将流量平均分配给所有可用的 Pod，从而实现负载均衡。
Local 模式： 在 Local 模式下，流量将直接访问与请求最近的节点上运行的 Pod。这种方式避免了负载均衡器的介入，直接将流量定向到本地的 Pod 上。这样可以减少延迟，并且在负载均衡器发生故障时仍然保持可用性。
区别 两种模式有什么区别呢？
Cluster 模式 Cluster 模式是默认的模式，Kube-proxy 不管容器在哪个节点上，会公平的转发到某一个节点上，在转发时会替换掉源 ip，变成转发的上一个节点的 ip.原因是 Kube-proxy 在做转发的时候，会做一次 SNAT (source network address translation)，所以源 ip 变成了上一个节点的 ip 地址。
这个模式的优点是负载均衡比较好，缺点是由于转发，可能会有性能损耗。
Local 模式 Local 模式下，请求只转发给本机的容器，不会转发给其它节点的容器，保留了源 ip。
...</p></div><footer class=entry-footer><span title='2023-12-03 09:48:07 +0800 +0800'>十二月 3, 2023</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;overstarry</footer><a class=entry-link aria-label="post link to Kubernetes externaltrafficpolicy 简介" href=https://jasminides.com/posts/kubernetes-externaltrafficpolicy-%E7%AE%80%E4%BB%8B/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://jasminides.com/page/3/>«&nbsp;上一页&nbsp;
</a><a class=next href=https://jasminides.com/page/5/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>Copyright © 2024-now - overstarry · All rights reserved<br></span>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>